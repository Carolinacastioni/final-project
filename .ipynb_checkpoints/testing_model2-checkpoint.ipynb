{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import face_recognition\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importNewPath(folder):\n",
    "    path = f\"treated_images/{folder}/*.jpg\"\n",
    "    print(path)\n",
    "    faceFiles = glob.glob(path)\n",
    "    return faceFiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treated_images/0-2/*.jpg\n",
      "treated_images/4-6/*.jpg\n",
      "treated_images/8-12/*.jpg\n",
      "treated_images/15-20/*.jpg\n",
      "treated_images/25-32/*.jpg\n",
      "treated_images/38-43/*.jpg\n",
      "treated_images/48-53/*.jpg\n",
      "treated_images/60-100/*.jpg\n"
     ]
    }
   ],
   "source": [
    "folders = ['0-2', '4-6', '8-12', '15-20', '25-32', '38-43', '48-53', '60-100']\n",
    "\n",
    "faceFiles = []\n",
    "    \n",
    "for files in folders:\n",
    "    ff = importNewPath(files)\n",
    "    faceFiles.append(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics = dict()\n",
    "for ffiles in faceFiles:\n",
    "    for foto in ffiles:\n",
    "        label = foto.split(\"/\")[-2]\n",
    "        pic = foto\n",
    "        if label in pics:\n",
    "            pics[label].append(pic)\n",
    "        else:\n",
    "            pics[label] = [pic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>foto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-2</td>\n",
       "      <td>treated_images/0-2/image_669.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-2</td>\n",
       "      <td>treated_images/0-2/image_1570.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-2</td>\n",
       "      <td>treated_images/0-2/image_346.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-2</td>\n",
       "      <td>treated_images/0-2/image_441.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-2</td>\n",
       "      <td>treated_images/0-2/image_1055.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                               foto\n",
       "0   0-2   treated_images/0-2/image_669.jpg\n",
       "1   0-2  treated_images/0-2/image_1570.jpg\n",
       "2   0-2   treated_images/0-2/image_346.jpg\n",
       "3   0-2   treated_images/0-2/image_441.jpg\n",
       "4   0-2  treated_images/0-2/image_1055.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = []\n",
    "\n",
    "for k,v in pics.items():\n",
    "    for a in v:\n",
    "        im.append([k,a])\n",
    "faces_df =  pd.DataFrame(im, columns=[\"label\",\"foto\"])\n",
    "\n",
    "display(faces_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-32     5023\n",
       "0-2       2491\n",
       "38-43     2340\n",
       "4-6       2140\n",
       "8-12      2124\n",
       "15-20     1642\n",
       "60-100     872\n",
       "48-53      830\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "def extractFace(picFile, debug=False):\n",
    "    im = cv2.imread(picFile)    \n",
    "    im_bw = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(im_bw, 2, 4)\n",
    "    if len(faces) == 0:\n",
    "        print(f\"Warning: no face detected on {picFile}\")\n",
    "        return \n",
    "    if debug:\n",
    "        print(faces)\n",
    "    selected_face = faces[0]\n",
    "    discard_faces = faces[1:]\n",
    "    if debug:\n",
    "        for (x,y,w,h) in faces:\n",
    "            im = cv2.rectangle(im,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            cara = im_bw[y:y+h, x:x+w]\n",
    "            roi_color = im[y:y+h, x:x+w]\n",
    "        plt.imshow(im)\n",
    "    return cara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMyFace(facesImages, label):\n",
    "    plt.figure(figsize=(20,5))\n",
    "    for i,a in enumerate(facesImages):\n",
    "        plt.subplot(1,len(facesImages), i + 1)\n",
    "        plt.imshow(a, cmap=\"gray\")\n",
    "        plt.title(f\"Face of {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFiles(files, dim=(60,60)):\n",
    "    output_faces = []\n",
    "    for incomingFile in files: \n",
    "        face = extractFace(incomingFile, debug=True)\n",
    "        if  isinstance(face, np.ndarray):\n",
    "            face = cv2.resize(face, dim)\n",
    "            output_faces.append(face)\n",
    "    return output_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected non-detected faces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
